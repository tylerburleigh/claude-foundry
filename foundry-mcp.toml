# foundry-mcp Configuration
#
# Provider priority with model selection for AI consultation workflows.

[workspace]
specs_dir = "./specs"
bikelane = "/bikelane"

[logging]
level = "INFO"
structured = true

[context]
# Auto-compact mode affects context percentage calculation
# true (default): denominator is 155k (Claude compacts before hitting limit)
# false: denominator is 200k (full context window, no auto-compaction)
auto_compact = true

[tools]
# Disable specific tools to reduce context window usage
# List tool names (without mcp__plugin_foundry_foundry-mcp__ prefix)
# Available: health, plan, pr, error, metrics, journal, authoring, review,
#            spec, task, provider, environment, lifecycle, verification,
#            server, test, research
disabled_tools = ["error", "metrics", "health", "environment"]
# Environment variable alternative: FOUNDRY_MCP_DISABLED_TOOLS (comma-separated)

[workflow]
mode = "task"
auto_validate = true
journal_enabled = true

[implement]
# Default flags for /implement command (can be overridden via CLI flags)
auto = false      # --auto: skip prompts between tasks
delegate = true   # --delegate: use subagent(s) for implementation
parallel = false  # --parallel: run subagents concurrently (implies delegate)

[consultation]
# Provider priority list - first available provider wins
# Format: "[api]provider/model" or "[cli]transport[:backend/model|:model]"
priority = [
    "[cli]codex:gpt-5.2-codex",
    "[cli]opencode:gpt-5.2-codex",
    "[cli]gemini:pro",
    "[cli]cursor-agent:composer-1",
    "[cli]claude:opus",
]

# Operational settings
default_timeout = 300

[research]
# Research tool configuration (chat, consensus, thinkdeep, ideate, deep)
# Uses same format as consultation: "[cli]provider:model"
default_provider = "[cli]codex:gpt-5.2-codex"
consensus_providers = [
    "[cli]codex:gpt-5.2-codex",
    "[cli]opencode:gpt-5.2-codex",
    "[cli]gemini:pro",
    "[cli]cursor-agent:composer-1",
    "[cli]claude:opus",
]
max_retries = 2
retry_delay = 5.0
fallback_enabled = true
cache_ttl = 3600

[research.deep]
# Deep research workflow settings
max_iterations = 3
max_sub_queries = 5
max_sources_per_query = 5
follow_links = true
max_concurrent = 3
timeout_per_operation = 120

# Per-workflow consultation configuration
# Each workflow can specify min_models for consensus and timeout override

# Fidelity review requires 2 models for consensus to catch implementation deviations
[consultation.workflows.fidelity_review]
min_models = 2
timeout_override = 600.0

# Plan review requires 2 models for consensus on architectural decisions
[consultation.workflows.plan_review]
min_models = 2
timeout_override = 180.0

# Markdown plan review (pre-spec) requires 2 models for consensus
[consultation.workflows.markdown_plan_review]
min_models = 2
timeout_override = 180.0

# Doc generation uses single model (default min_models=1)
[consultation.workflows.doc_generation]
min_models = 1

[git]
enabled = true
commit_cadence = "task"

# Error collection - stores error logs for dashboard visibility
[error_collection]
enabled = true
storage_path = "~/.foundry-mcp/errors"
retention_days = 30
max_records = 10000

# Metrics persistence - stores metrics for dashboard charts
[metrics_persistence]
enabled = true
storage_path = "~/.foundry-mcp/metrics"
retention_days = 7
max_records = 50000
